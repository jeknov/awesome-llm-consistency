<img src="https://awesome.re/badge.svg"/> <img src=https://img.shields.io/badge/PRs-welcome-green alt="img" style="zoom:100%; vertical-align: middle" /> <img src=https://img.shields.io/badge/License-MIT-lightgrey alt="img" style="zoom:100%; vertical-align: middle" />
# Awesome LLM Consistency
A curated list of papers and resources about the consistency of large language models.

## Table of contents
- [Papers](#papers)
- [Datasets / Benchmarks](#datasets--benchmarks)
- [Other](#other)

## Papers
### 2020
- <img src=https://img.shields.io/badge/ACL-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2020.acl-main.499/" target="_blank">Logic-Guided Data Augmentation and Regularization for Consistent Question Answering</a>, </br>by *Asai, A., & Hajishirzi, H.*
- <img src=https://img.shields.io/badge/ACL-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2020.acl-main.382/" target="_blank">Make Up Your Mind! Adversarial Generation of Inconsistent Natural Language Explanations</a>, </br>by *Camburu, O. M., Shillingford, B., Minervini, P., Lukasiewicz, T., & Blunsom, P.*
- <img src=https://img.shields.io/badge/ACL-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2020.acl-main.450/" target="_blank">Asking and Answering Questions to Evaluate the Factual Consistency of Summaries</a>, </br>by *Wang, A., Cho, K., & Lewis, M.*

### 2021
- <img src=https://img.shields.io/badge/TACL-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2021.tacl-1.60" target="_blank">Measuring and improving consistency in pretrained language models</a>, </br>by *Elazar, Y., Kassner, N., Ravfogel, S., Ravichander, A., Hovy, E., Schütze, H., & Goldberg, Y.*

### 2022
- <img src=https://img.shields.io/badge/COLING-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2022.coling-1.324.pdf" target="_blank">BECEL: Benchmark for consistency evaluation of language models</a>, </br>by *Jang, M., Kwon, D. S., & Lukasiewicz, T*.
- <img src=https://img.shields.io/badge/NeurIPS_workshop-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://openreview.net/forum?id=SgbpddeEV-C" target="_blank">Measuring Reliability of Large Language Models through Semantic Consistency</a>, </br>by *Raj, H., Rosati, D., & Majumdar, S.*.
- <img src=https://img.shields.io/badge/arXiv-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2211.08412" target="_blank">Evaluating the factual consistency of large language models through summarization</a>, </br>by *Tam, D., Mascarenhas, A., Zhang, S., Kwan, S., Bansal, M., & Raffel, C.*.
- <img src=https://img.shields.io/badge/ICLR-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://openreview.net/forum?id=1PL1NIMMrw" target="_blank">Self-Consistency Improves Chain of Thought Reasoning in Language Models</a>, </br>by *Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou*.
- <img src=https://img.shields.io/badge/ACL_Findings-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2022.findings-acl.240/" target="blank">Factual Consistency of Multilingual Pretrained Language Models</a>, </br>by *Constanza Fierro, Anders Søgaard*.


### 2023
- <img src=https://img.shields.io/badge/ICLR-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/pdf/2310.01846.pdf" target="_blank">Benchmarking and improving generator-validator consistency of language models</a>, </br>by *Li, X. L., Shrivastava, V., Li, S., Hashimoto, T., & Liang, P.*
- <img src=https://img.shields.io/badge/EMNLP-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2023.emnlp-main.991" target="_blank">Consistency Analysis of ChatGPT</a>, </br>by *Jang, M., & Lukasiewicz, T.*
- <img src=https://img.shields.io/badge/ACL-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2023.acl-long.769/" target="_blank">Measuring Consistency in Text-based Financial Forecasting Models</a>, </br>by *Yang, L., Ma, Y., & Zhang, Y.*
- <img src=https://img.shields.io/badge/arXiv-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2308.09138" target="_blank">Semantic consistency for assuring reliability of large language models</a>, </br>by *Raj, H., Gupta, V., Rosati, D., & Majumdar, S.*
- <img src=https://img.shields.io/badge/EMNLP-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2303.08896" target="_blank">SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models</a>, </br>by *Potsawee Manakul, Adian Liusie, Mark J. F. Gales*


### 2024
- <img src=https://img.shields.io/badge/ICLR-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://openreview.net/forum?id=GPKTIktA0k" target="_blank">The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”</a>, </br>by *Berglund, L., Tong, M., Kaufmann, M., Balesni, M., Stickland, A. C., Korbak, T., & Evans, O.*
- <img src=https://img.shields.io/badge/ICLR-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://openreview.net/forum?id=CF8H8MS5P8" target="_blank">The Generative AI Paradox:“What It Can Create, It May Not Understand”</a>, </br>by *Peter West, Ximing Lu, Nouha Dziri, Faeze Brahman, Linjie Li, Jena D. Hwang, Liwei Jiang, Jillian Fisher, Abhilasha Ravichander, Khyathi Chandu, Benjamin Newman, Pang Wei Koh, Allyson Ettinger, Yejin Choi*
- <img src=https://img.shields.io/badge/ICLR-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://openreview.net/forum?id=EmQSOi1X2f" target="_blank">Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation</a>, </br>by *Mündler, N., He, J., Jenko, S., & Vechev, M.*
- <img src=https://img.shields.io/badge/arXiv-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/pdf/2401.02009.pdf" target="_blank">Self-contrast: Better reflection through inconsistent solving perspectives</a>, </br>by *Zhang, W., Shen, Y., Wu, L., Peng, Q., Wang, J., Zhuang, Y., & Lu, W.*
- <img src=https://img.shields.io/badge/arXiv-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2311.09603" target="_blank">Self-Contradictory Reasoning Evaluation and Detection</a>, </br>by *Liu, Z., Lee, I., Du, Y., Sanyal, S., & Zhao, J.*
- <img src=https://img.shields.io/badge/arXiv-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2401.10353" target="_blank">Inconsistent dialogue responses and how to recover from them</a>, </br>by *Zhang, M., Jin, L., Song, L., Mi, H., & Yu, D.*
- <img src=https://img.shields.io/badge/arXiv-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2311.16842" target="_blank">RELIC: Investigating Large Language Model Responses using Self-Consistency</a>, </br>by *Cheng, F., Zouhar, V., Arora, S., Sachan, M., Strobelt, H., & El-Assady, M.*
- <img src=https://img.shields.io/badge/arXiv-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2401.02132" target="_blank">DCR-Consistency: Divide-Conquer-Reasoning for Consistency Evaluation and Improvement of Large Language Models</a>, </br>by *Cui, W., Zhang, J., Li, Z., Damien, L., Das, K., Malin, B., & Kumar, S.*
- <img src=https://img.shields.io/badge/TMLR-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://openreview.net/forum?id=5nBqY1y96B" target="_blank">Two Failures of Self-Consistency in the Multi-Step Reasoning of LLMs</a>, </br>by *Angelica Chen, Jason Phang, Alicia Parrish, Vishakh Padmakumar, Chen Zhao, Samuel R. Bowman, Kyunghyun Cho*

## Datasets / Benchmarks

| **Name** | **Consistency type assessed**                                                                           | **Tasks assessed**                                                                                                                               | **URL**                                |
|----------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------|
| BECEL    | - semantic<br>- logical negational<br>- logical symmetric<br>- logical transitive<br>- logical additive | - NLI<br>- semantic textual similarity<br>- words-in-context<br>- semantic analysis<br>- machine reading comprehension<br>- topic classification | https://github.com/MJ-Jang/BECEL       |
| ParaRel  | semantic                                                                                                | relations in knowledge bases                                                                                                                     | https://github.com/yanaiela/pararel    |
| mParaRel | - factual<br>- semantic                                                                                 | relations in multilingual knowledge bases                                                                                                        | https://github.com/coastalcph/mpararel |

## Other
### Other relevant awesome lists
- [Awesome LLM Evaluation](https://github.com/onejune2018/Awesome-LLM-Eval)
- [Awesome LLM hallucination](https://github.com/LuckyyySTA/Awesome-LLM-hallucination)
- [Factuality in Large Language Models](https://github.com/wangcunxiang/LLM-Factuality-Survey)
- [LLMs meet misinformation](https://github.com/llm-misinformation/llm-misinformation-survey)
- [Awesome LLM reasoning](https://github.com/luban-agi/Awesome-LLM-reasoning)
