<img src="https://awesome.re/badge.svg"/> <img src=https://img.shields.io/badge/PRs-welcome-green alt="img" style="zoom:100%; vertical-align: middle" /> <img src=https://img.shields.io/badge/License-MIT-lightgrey alt="img" style="zoom:100%; vertical-align: middle" />
# Awesome LLM Consistency
A curated list of papers and resources about the consistency of large language models.

## Table of contents
- [Papers](#papers)
- [Datasets / Benchmarks](#datasets--benchmarks)
- [Other](#other)

## Papers
### 2020
- <img src=https://img.shields.io/badge/ACL-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2020.acl-main.499/" target="_blank">Logic-Guided Data Augmentation and Regularization for Consistent Question Answering</a>, </br>by *Asai, A., & Hajishirzi, H.*
- <img src=https://img.shields.io/badge/ACL-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2020.acl-main.382/" target="_blank">Make Up Your Mind! Adversarial Generation of Inconsistent Natural Language Explanations</a>, </br>by *Camburu, O. M., Shillingford, B., Minervini, P., Lukasiewicz, T., & Blunsom, P.*
- <img src=https://img.shields.io/badge/ACL-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2020.acl-main.450/" target="_blank">Asking and Answering Questions to Evaluate the Factual Consistency of Summaries</a>, </br>by *Wang, A., Cho, K., & Lewis, M.*

### 2021
- <img src=https://img.shields.io/badge/TACL-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2021.tacl-1.60" target="_blank">Measuring and improving consistency in pretrained language models</a>, </br>by *Elazar, Y., Kassner, N., Ravfogel, S., Ravichander, A., Hovy, E., Schütze, H., & Goldberg, Y.*
- <img src=https://img.shields.io/badge/NAACL-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2021.naacl-main.194/" target="_blank">Improving Generation and Evaluation of Visual Stories via Semantic Consistency</a>, </br>by *Adyasha Maharana, Darryl Hannan, Mohit Bansal*


### 2022
- <img src=https://img.shields.io/badge/COLING-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2022.coling-1.324.pdf" target="_blank">BECEL: Benchmark for consistency evaluation of language models</a>, </br>by *Jang, M., Kwon, D. S., & Lukasiewicz, T*.
- <img src=https://img.shields.io/badge/NeurIPS_workshop-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://openreview.net/forum?id=SgbpddeEV-C" target="_blank">Measuring Reliability of Large Language Models through Semantic Consistency</a>, </br>by *Raj, H., Rosati, D., & Majumdar, S.*.
- <img src=https://img.shields.io/badge/arXiv-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2211.08412" target="_blank">Evaluating the factual consistency of large language models through summarization</a>, </br>by *Tam, D., Mascarenhas, A., Zhang, S., Kwan, S., Bansal, M., & Raffel, C.*.
- <img src=https://img.shields.io/badge/ICLR-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://openreview.net/forum?id=1PL1NIMMrw" target="_blank">Self-Consistency Improves Chain of Thought Reasoning in Language Models</a>, </br>by *Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou*.
- <img src=https://img.shields.io/badge/ACL_Findings-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2022.findings-acl.240/" target="blank">Factual Consistency of Multilingual Pretrained Language Models</a>, </br>by *Constanza Fierro, Anders Søgaard*.
- <img src=https://img.shields.io/badge/EMNLP-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2022.emnlp-main.115/" target="blank">Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference</a>, </br>by *Eric Mitchell, Joseph J. Noh, Siyan Li, William S. Armstrong, Ananth Agarwal, Patrick Liu, Chelsea Finn, Christopher D. Manning*.
- <img src=https://img.shields.io/badge/arXiv-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2210.15235" target="blank">SSD: Towards Better Text-Image Consistency Metric in Text-to-Image Generation</a>, </br>by *Zhaorui Tan, Xi Yang, Zihan Ye, Qiufeng Wang, Yuyao Yan, Anh Nguyen, Kaizhu Huang*.


### 2023
- <img src=https://img.shields.io/badge/ICLR-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/pdf/2310.01846.pdf" target="_blank">Benchmarking and improving generator-validator consistency of language models</a>, </br>by *Li, X. L., Shrivastava, V., Li, S., Hashimoto, T., & Liang, P.*
- <img src=https://img.shields.io/badge/ACL-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2023.acl-long.769/" target="_blank">Measuring Consistency in Text-based Financial Forecasting Models</a>, </br>by *Yang, L., Ma, Y., & Zhang, Y.*
- <img src=https://img.shields.io/badge/arXiv-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2308.09138" target="_blank">Semantic consistency for assuring reliability of large language models</a>, </br>by *Raj, H., Gupta, V., Rosati, D., & Majumdar, S.*
- <img src=https://img.shields.io/badge/EMNLP-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2303.08896" target="_blank">SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models</a>, </br>by *Potsawee Manakul, Adian Liusie, Mark J. F. Gales*
- <img src=https://img.shields.io/badge/EMNLP-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2023.emnlp-main.332/" target="_blank">The Effect of Scaling, Retrieval Augmentation and Form on the Factual Consistency of Language Models</a>, </br>by *Lovisa Hagström, Denitsa Saynova, Tobias Norlund, Moa Johansson, Richard Johansson*
- <img src=https://img.shields.io/badge/EMNLP-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2023.emnlp-main.991" target="_blank">Consistency Analysis of ChatGPT</a>, </br>by *Jang, M., & Lukasiewicz, T.*
- <img src=https://img.shields.io/badge/EMNLP-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2023.emnlp-main.658" target="_blank">Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models</a>, </br>by *Jirui Qi, Raquel Fernández, Arianna Bisazza*
- <img src=https://img.shields.io/badge/ICLR-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://openreview.net/forum?id=1PL1NIMMrw" target="_blank">Self-Consistency Improves Chain of Thought Reasoning in Language Models</a>, </br>by *Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou*
- <img src=https://img.shields.io/badge/EMNLP-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2023.emnlp-main.761/" target="_blank">Let’s Sample Step by Step: Adaptive-Consistency for Efficient Reasoning and Coding with LLMs</a>, </br>by *Pranjal Aggarwal, Aman Madaan, Yiming Yang, Mausam*
- <img src=https://img.shields.io/badge/CoNLL-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2023.conll-1.20/" target="_blank">Mind the instructions: a holistic evaluation of consistency and interactions in prompt-based learning</a>, </br>by *Lucas Weber, Elia Bruni, Dieuwke Hupkes*
- <img src=https://img.shields.io/badge/ScienceDirect-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://www.sciencedirect.com/science/article/abs/pii/S1551741123003650" target="_blank">Assessing the accuracy and consistency of ChatGPT in clinical pharmacy management: A preliminary analysis with clinical pharmacy experts worldwide</a>, </br>by *Zahraa Al-Dujaili, Sarah Omari, Jey Pillai, Achraf Al Faraj*
- <img src=https://img.shields.io/badge/arXiv-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2311.17311" target="_blank">Universal Self-Consistency for Large Language Model Generation</a>, </br>by *Xinyun Chen, Renat Aksitov, Uri Alon, Jie Ren, Kefan Xiao, Pengcheng Yin, Sushant Prakash, Charles Sutton, Xuezhi Wang, Denny Zhou*
- <img src=https://img.shields.io/badge/EMNLP_workshop-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://aclanthology.org/2023.gem-1.22/" target="_blank">Separating form and meaning: Using self-consistency to quantify task understanding across multiple senses</a>, </br>by *Xenia Ohmer, Elia Bruni, Dieuwke Hupkes*


### 2024
- <img src=https://img.shields.io/badge/ICLR-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://openreview.net/forum?id=GPKTIktA0k" target="_blank">The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”</a>, </br>by *Berglund, L., Tong, M., Kaufmann, M., Balesni, M., Stickland, A. C., Korbak, T., & Evans, O.*
- <img src=https://img.shields.io/badge/ICLR-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://openreview.net/forum?id=caW7LdAALh" target="_blank">Beyond Accuracy: Evaluating Self-Consistency of Code Large Language Models with IdentityChain</a>, </br>by *Marcus J. Min, Yangruibo Ding, Luca Buratti, Saurabh Pujar, Gail Kaiser, Suman Jana, Baishakhi Ray*
- <img src=https://img.shields.io/badge/ICLR-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://openreview.net/forum?id=CF8H8MS5P8" target="_blank">The Generative AI Paradox:“What It Can Create, It May Not Understand”</a>, </br>by *Peter West, Ximing Lu, Nouha Dziri, Faeze Brahman, Linjie Li, Jena D. Hwang, Liwei Jiang, Jillian Fisher, Abhilasha Ravichander, Khyathi Chandu, Benjamin Newman, Pang Wei Koh, Allyson Ettinger, Yejin Choi*
- <img src=https://img.shields.io/badge/ICLR-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://openreview.net/forum?id=EmQSOi1X2f" target="_blank">Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation</a>, </br>by *Mündler, N., He, J., Jenko, S., & Vechev, M.*
- <img src=https://img.shields.io/badge/arXiv-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/pdf/2401.02009.pdf" target="_blank">Self-contrast: Better reflection through inconsistent solving perspectives</a>, </br>by *Zhang, W., Shen, Y., Wu, L., Peng, Q., Wang, J., Zhuang, Y., & Lu, W.*
- <img src=https://img.shields.io/badge/arXiv-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2311.09603" target="_blank">Self-Contradictory Reasoning Evaluation and Detection</a>, </br>by *Liu, Z., Lee, I., Du, Y., Sanyal, S., & Zhao, J.*
- <img src=https://img.shields.io/badge/arXiv-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2401.10353" target="_blank">Inconsistent dialogue responses and how to recover from them</a>, </br>by *Zhang, M., Jin, L., Song, L., Mi, H., & Yu, D.*
- <img src=https://img.shields.io/badge/arXiv-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2311.16842" target="_blank">RELIC: Investigating Large Language Model Responses using Self-Consistency</a>, </br>by *Cheng, F., Zouhar, V., Arora, S., Sachan, M., Strobelt, H., & El-Assady, M.*
- <img src=https://img.shields.io/badge/arXiv-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2401.02132" target="_blank">DCR-Consistency: Divide-Conquer-Reasoning for Consistency Evaluation and Improvement of Large Language Models</a>, </br>by *Cui, W., Zhang, J., Li, Z., Damien, L., Das, K., Malin, B., & Kumar, S.*
- <img src=https://img.shields.io/badge/TMLR-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://openreview.net/forum?id=5nBqY1y96B" target="_blank">Two Failures of Self-Consistency in the Multi-Step Reasoning of LLMs</a>, </br>by *Angelica Chen, Jason Phang, Alicia Parrish, Vishakh Padmakumar, Chen Zhao, Samuel R. Bowman, Kyunghyun Cho*
- <img src=https://img.shields.io/badge/arXiv-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2402.11279" target="_blank">Multi-Perspective Consistency Enhances Confidence Estimation in Large Language Models</a>, </br>by *Pei Wang, Yejie Wang, Muxi Diao, Keqing He, Guanting Dong, Weiran Xu*
- <img src=https://img.shields.io/badge/CogSIMA-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://ieeexplore.ieee.org/abstract/document/10553903" target="_blank">Probing the Consistency of Situational Information Extraction with Large Language Models: A Case Study on Crisis Computing</a>, </br>by *Andrea Salfinger, Lauro Snidaro*
- <img src=https://img.shields.io/badge/ACL-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2402.13212" target="_blank">Soft Self-Consistency Improves Language Model Agents</a>, </br>by *Han Wang, Archiki Prasad, Elias Stengel-Eskin, Mohit Bansal*
- <img src=https://img.shields.io/badge/NAACL-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2310.07712" target="_blank">Found in the Middle: Permutation Self-Consistency Improves Listwise Ranking in Large Language Models</a>, </br>by *Raphael Tang, Xinyu Zhang, Xueguang Ma, Jimmy Lin, Ferhan Ture*
- <img src=https://img.shields.io/badge/arXiv-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2402.13904" target="_blank">Calibrating Large Language Models with Sample Consistency</a>, </br>by *Qing Lyu, Kumar Shridhar, Chaitanya Malaviya, Li Zhang, Yanai Elazar, Niket Tandon, Marianna Apidianaki, Mrinmaya Sachan, Chris Callison-Burch*
- <img src=https://img.shields.io/badge/LREC_COLING-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2402.13709" target="_blank">SaGE: Evaluating Moral Consistency in Large Language Models</a>, </br>by *Vamshi Krishna Bonagiri, Sreeram Vennam, Priyanshul Govil, Ponnurangam Kumaraguru, Manas Gaur*
- <img src=https://img.shields.io/badge/SaTML-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://ieeexplore.ieee.org/abstract/document/10516635" target="_blank">Evaluating Superhuman Models with Consistency Checks</a>, </br>by *Lukas Fluri; Daniel Paleka; Florian Tramèr*
- <img src=https://img.shields.io/badge/EACL_workshop-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2402.02896" target="_blank">LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models</a>, </br>by *Ivar Frisch, Mario Giulianelli*
- <img src=https://img.shields.io/badge/arXiv-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/abs/2309.17272" target="_blank">Enhancing Large Language Models in Coding Through Multi-Perspective Self-Consistency</a>, </br>by *Baizhou Huang, Shuai Lu, Weizhu Chen, Xiaojun Wan, Nan Duan*
- <img src=https://img.shields.io/badge/arXiv-blue alt="img" style="zoom:100%; vertical-align: middle" /> <a href="https://arxiv.org/pdf/2404.12145" target="_blank">From form(s) to meaning: Probing the semantic depths of language models using multisense consistency</a>, </br>by *Xenia Ohmer, Elia Bruni, Dieuwke Hupkes*



## Datasets / Benchmarks

| **Name** | **Consistency type assessed**                                                                           | **Tasks assessed**                                                                                                                               | **URL**                                |
|----------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------|
| BECEL    | - semantic<br>- logical negational<br>- logical symmetric<br>- logical transitive<br>- logical additive | - NLI<br>- semantic textual similarity<br>- words-in-context<br>- semantic analysis<br>- machine reading comprehension<br>- topic classification | https://github.com/MJ-Jang/BECEL       |
| ParaRel  | semantic                                                                                                | relations in knowledge bases                                                                                                                     | https://github.com/yanaiela/pararel    |
| mParaRel | - factual<br>- semantic                                                                                 | relations in multilingual knowledge bases                                                                                                        | https://github.com/coastalcph/mpararel |
| Moral Consistency Corpus (MCC) | - semantic                                                                                 | moral question answering                                                                                                        | https://github.com/vnnm404/SaGE |

## Other
### Other relevant awesome lists
- [Awesome LLM Evaluation](https://github.com/onejune2018/Awesome-LLM-Eval)
- [Awesome LLM hallucination](https://github.com/LuckyyySTA/Awesome-LLM-hallucination)
- [Factuality in Large Language Models](https://github.com/wangcunxiang/LLM-Factuality-Survey)
- [LLMs meet misinformation](https://github.com/llm-misinformation/llm-misinformation-survey)
- [Awesome LLM reasoning](https://github.com/luban-agi/Awesome-LLM-reasoning)
